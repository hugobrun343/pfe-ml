# Preprocessing Configuration - 256x256x32 (Split 3: run_20260120_134559)

paths:
  dataset_json: "/mnt/pve/ds_shared/dataset_enriched_FINAL.json"
  split_json: "../split-dataset/output/run_testdataset/train_test_split.json"
  data_root: "/mnt/pve/ds_shared/data/raw"
  output_dir: "/mnt/pve/ds_shared/data/preprocess"

preprocessing:
  # Target size: H × W × D
  target_height: 256
  target_width: 256
  target_depth: 32
  
  # Patch extraction: n_h × n_w = total patches per volume
  n_patches_h: 4
  n_patches_w: 4
  
  # Slice selection: intensity, variance, entropy, gradient
  slice_selection: "intensity"
  
  # Normalization: z-score, min-max
  normalization: "z-score"

# Output: Each patch is saved as a separate .nii.gz file
# Structure: output/preprocessed_{H}x{W}x{D}_{timestamp}/train/ and test/
# Metadata: patches_info.json contains split, stack_id, label, position_i, position_j for each patch
