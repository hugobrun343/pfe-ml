# Preprocessing Configuration - 256x256x32
# Preprocessing unique pour tous les volumes (pas de séparation train/test)
# Les splits seront utilisés lors du chargement des données

paths:
  dataset_json: "/mnt/pve/ds_shared/dataset_enriched_FINAL.json"
  data_root: "/mnt/pve/ds_shared/data/raw"
  output_dir: "/mnt/pve/ds_shared/data/preprocess"

preprocessing:
  # Target size: H × W × D
  target_height: 256
  target_width: 256
  target_depth: 32
  
  # Patch extraction: n_h × n_w = total patches per volume
  n_patches_h: 4
  n_patches_w: 4
  
  # Slice selection: intensity, variance, entropy, gradient
  slice_selection: "intensity"
  
  # Normalization: z-score, min-max
  normalization: "z-score"

# Output: Each patch is saved as a separate .nii.gz file
# Structure: output/preprocessed_{H}x{W}x{D}_{timestamp}/patches/
# Metadata: patches_info.json contains stack_id, label, position_i, position_j for each patch
# Use train_test_split.json during data loading to filter patches by split
